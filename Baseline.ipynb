{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import tensorboard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import keras\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling1D, Lambda, UpSampling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Input,Flatten,Dense, Dropout, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files_list(directory):\n",
    "    '''\n",
    "    Load the audiofiles inside a directory.\n",
    "    '''\n",
    "    return os.listdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the descriptors (1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = '/home/belen_alastruey/PYTHON/Autoencoder/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DIRECTORY + 'MEL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_files_list(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors= []\n",
    "#labels = []\n",
    "for file in files:\n",
    "    if \"slider\" in file: #slider_id00\n",
    "        descr = np.load(path + file)\n",
    "        descriptors.append(descr)\n",
    "        #labels.append(re.split(r'_', file)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = np.asarray(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2670, 128, 216)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test= train_test_split(descr,test_size=0.15, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2269, 128, 216)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for n in range(X_train.shape[0]):\n",
    "    for i in range(211):\n",
    "        a = []\n",
    "        a.append([X_train[n,:,i],X_train[n,:,i+1],X_train[n,:,i+2],X_train[n,:,i+3],X_train[n,:,i+4]])\n",
    "        a = np.asarray(a)\n",
    "        a = a.reshape(640)\n",
    "        inputs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.asarray(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478759, 640)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = []\n",
    "for n in range(X_test.shape[0]):\n",
    "    for i in range(211):\n",
    "        a = []\n",
    "        a.append([X_test[n,:,i],X_test[n,:,i+1],X_test[n,:,i+2],X_test[n,:,i+3],X_test[n,:,i+4]])\n",
    "        a = np.asarray(a)\n",
    "        a = a.reshape(640)\n",
    "        inputs_test.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = np.asarray(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84611, 640)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction as in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inputDim):\n",
    "    \"\"\"\n",
    "    define the keras model\n",
    "    the model based on the simple dense auto encoder \n",
    "    (128*128*128*128*8*128*128*128*128)\n",
    "    \"\"\"\n",
    "    inputLayer = Input(shape=(inputDim,))\n",
    "\n",
    "    h = Dense(128)(inputLayer)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    h = Dense(8)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(128)(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Activation('relu')(h)\n",
    "\n",
    "    h = Dense(inputDim)(h)\n",
    "\n",
    "    return Model(inputs=inputLayer, outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = get_model(640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 640)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 640)               82560     \n",
      "=================================================================\n",
      "Total params: 269,992\n",
      "Trainable params: 267,928\n",
      "Non-trainable params: 2,064\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(baseline.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.compile(optimizer=Adam(learning_rate = 0.001) , loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 100\n",
    "bs = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "936/936 [==============================] - 20s 22ms/step - loss: 377.1604 - mae: 11.9427\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 20s 22ms/step - loss: 14.9029 - mae: 2.8322\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 17s 19ms/step - loss: 12.1072 - mae: 2.5204\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 10.8204 - mae: 2.3886\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 9.7281 - mae: 2.2805\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 8.7959 - mae: 2.1818\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 8.3334 - mae: 2.1285\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 8.1416 - mae: 2.1066\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 19s 20ms/step - loss: 7.8392 - mae: 2.0680\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 7.6676 - mae: 2.0481\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 7.5250 - mae: 2.0301\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 7.4300 - mae: 2.0186\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 7.3381 - mae: 2.0060\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 7.2571 - mae: 1.9949\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 7.1996 - mae: 1.9882\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 7.1377 - mae: 1.9807\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 7.0964 - mae: 1.9756\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 20s 21ms/step - loss: 7.0425 - mae: 1.9681\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 20s 21ms/step - loss: 7.0952 - mae: 1.9755\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 17s 19ms/step - loss: 6.9776 - mae: 1.9585\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.9496 - mae: 1.9554\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.9070 - mae: 1.9482\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 21s 23ms/step - loss: 6.9039 - mae: 1.9484\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 22s 24ms/step - loss: 6.8854 - mae: 1.9452\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.8504 - mae: 1.9409\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.8114 - mae: 1.9345\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.7922 - mae: 1.9326\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.7695 - mae: 1.9286\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.7631 - mae: 1.9282\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.7393 - mae: 1.9246\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.7286 - mae: 1.9232\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.7100 - mae: 1.9208\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6896 - mae: 1.9172\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6925 - mae: 1.9178\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6704 - mae: 1.9138\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6539 - mae: 1.9121\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.6483 - mae: 1.9111\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6308 - mae: 1.9081\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6247 - mae: 1.9070\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6096 - mae: 1.9047\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.6143 - mae: 1.9061\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5990 - mae: 1.9031\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.6005 - mae: 1.9034\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.5753 - mae: 1.8990\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.5784 - mae: 1.9008\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5671 - mae: 1.8984\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5564 - mae: 1.8967\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5486 - mae: 1.8953\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5403 - mae: 1.8943\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.5369 - mae: 1.8938\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5308 - mae: 1.8925\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5258 - mae: 1.8918\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5102 - mae: 1.8890\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.5028 - mae: 1.8881\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.5005 - mae: 1.8875\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4984 - mae: 1.8877\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4906 - mae: 1.8863\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.4846 - mae: 1.8857\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.4778 - mae: 1.8840\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4731 - mae: 1.8836\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.4764 - mae: 1.8844\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 16s 18ms/step - loss: 6.4642 - mae: 1.8819\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.4632 - mae: 1.8817\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.4523 - mae: 1.8796\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.4497 - mae: 1.8803\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.4475 - mae: 1.8792\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4421 - mae: 1.8784\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4370 - mae: 1.8776\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4296 - mae: 1.8765\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4323 - mae: 1.8771\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.4243 - mae: 1.8756\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 18s 20ms/step - loss: 6.4228 - mae: 1.8743\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.4168 - mae: 1.8742\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 17s 19ms/step - loss: 6.4127 - mae: 1.8737\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4089 - mae: 1.8732\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4077 - mae: 1.8725\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4042 - mae: 1.8725\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.3976 - mae: 1.8710\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.3983 - mae: 1.8713\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.4032 - mae: 1.8728\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.3861 - mae: 1.8693\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.3845 - mae: 1.8686\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 17s 18ms/step - loss: 6.3825 - mae: 1.8687\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 17s 18ms/step - loss: 6.3814 - mae: 1.8689\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 19s 20ms/step - loss: 6.3810 - mae: 1.8685\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3760 - mae: 1.8683\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3692 - mae: 1.8660\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3686 - mae: 1.8666\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3663 - mae: 1.8659\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3650 - mae: 1.8663\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3610 - mae: 1.8655\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 19s 20ms/step - loss: 6.3607 - mae: 1.8648\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3562 - mae: 1.8642\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3545 - mae: 1.8645\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3530 - mae: 1.8639\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3464 - mae: 1.8625\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3489 - mae: 1.8635\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3467 - mae: 1.8632\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3423 - mae: 1.8624\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 18s 19ms/step - loss: 6.3390 - mae: 1.8615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f739185d7c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.fit(inputs, inputs,\n",
    "                epochs= nb_epochs,\n",
    "                batch_size= bs, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062/1062 [==============================] - 2s 2ms/step - loss: 6.8236 - mae: 1.9152\n",
      "[6.823550701141357, 1.9151898622512817]\n"
     ]
    }
   ],
   "source": [
    "score = baseline.evaluate(inputs_test, inputs_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.save('baseline_slider_allids.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
