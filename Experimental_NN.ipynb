{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental on Sound Event Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were training a deep CNN with only 2k data. The CNN tries to classificate this data into 5 different classes and it has a poor result. It would be more efficient to classify the sounds randomly.\n",
    "\n",
    "This problem combined with the huge cpu-consuming of train a CNN moves us into a cul-de-sac. \n",
    "\n",
    "But there's a glimmer of hope. And that's what we are going to try here.\n",
    "\n",
    "Our main objective here is the following: To reduce the complexity of the model by creating an image based on the mean of intensity in each frequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of what we are going to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, sr = librosa.load('../Datasets/s_a_d__datasets/audio_esc50/1-100210-B-36.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = librosa.feature.melspectrogram(y=dat, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 216)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.5993549e+02, 4.5912991e+02, 2.6354221e+02, ..., 2.5969156e+01,\n",
       "        1.8569384e+01, 8.6176844e+00],\n",
       "       [5.7142612e+01, 2.9574568e+01, 2.2764557e+01, ..., 3.1396091e+00,\n",
       "        3.3211610e+00, 8.9324789e+00],\n",
       "       [1.5904705e+01, 4.5833412e+01, 4.8435863e+01, ..., 5.5756366e-01,\n",
       "        6.3307798e-01, 7.3707592e-01],\n",
       "       ...,\n",
       "       [1.1063246e+00, 1.2394960e+00, 1.4005175e+00, ..., 1.1156948e-02,\n",
       "        7.8027854e-03, 4.8842449e-03],\n",
       "       [1.9012589e-02, 1.2849880e-02, 9.9226097e-03, ..., 2.2470423e-03,\n",
       "        1.4463906e-03, 1.5137937e-03],\n",
       "       [1.7806103e-02, 4.8770974e-03, 6.3218613e-04, ..., 1.5918356e-04,\n",
       "        1.8024274e-04, 3.4940013e-04]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = np.mean(arr.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = np.reshape(algo, (16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8423973e+02, 9.5221672e+01, 4.1524628e+01, 3.1253235e+01,\n",
       "        1.1174012e+01, 4.7411294e+00, 2.9177074e+00, 3.7878728e+00],\n",
       "       [4.1952629e+00, 4.0654149e+00, 5.6711202e+00, 7.9348154e+00,\n",
       "        8.6790867e+00, 5.7510371e+00, 7.8876605e+00, 7.0596685e+00],\n",
       "       [8.1930952e+00, 6.9106083e+00, 6.9541159e+00, 5.4830785e+00,\n",
       "        1.8071291e+01, 3.2125507e+01, 8.2721148e+00, 5.9156137e+00],\n",
       "       [4.7791600e+00, 4.8593578e+00, 4.6287632e+00, 3.1341968e+00,\n",
       "        2.0397530e+00, 2.2277358e+00, 4.3026896e+00, 4.6487260e+00],\n",
       "       [4.0277691e+00, 3.7509263e+00, 4.3718848e+00, 2.9770634e+00,\n",
       "        3.8824282e+00, 5.6923251e+00, 5.4853811e+00, 5.4030142e+00],\n",
       "       [6.5696130e+00, 1.0472785e+01, 4.7467525e+01, 1.0835682e+01,\n",
       "        6.4205809e+00, 6.2058992e+00, 5.6079807e+00, 4.0754209e+00],\n",
       "       [2.5316885e+00, 1.8539383e+00, 1.6581200e+00, 2.1909628e+00,\n",
       "        2.3071566e+00, 1.6815077e+00, 1.4791418e+00, 1.2806550e+00],\n",
       "       [1.3038816e+00, 1.5726756e+00, 1.4279604e+00, 3.3318408e+00,\n",
       "        2.6547067e+00, 2.4913359e+00, 2.5027094e+00, 2.0858927e+00],\n",
       "       [2.2238994e+00, 1.7900091e+00, 1.8007064e+00, 1.6938714e+00,\n",
       "        1.3974502e+00, 1.1551405e+00, 1.2180010e+00, 1.5042323e+00],\n",
       "       [1.5297906e+00, 1.5546106e+00, 1.2732008e+00, 1.0798564e+00,\n",
       "        1.2284745e+00, 1.8196040e+00, 2.2996805e+00, 1.6917516e+00],\n",
       "       [1.3730698e+00, 1.0716424e+00, 8.7843269e-01, 9.7666860e-01,\n",
       "        9.2199492e-01, 9.8743623e-01, 9.6470261e-01, 8.4882218e-01],\n",
       "       [8.3428931e-01, 1.3183656e+00, 1.5214828e+00, 3.9803936e+00,\n",
       "        5.4778042e+00, 2.5424016e+00, 2.5751102e+00, 2.1295938e+00],\n",
       "       [2.0528383e+00, 2.0842571e+00, 1.1206894e+02, 1.3485320e+02,\n",
       "        1.0556455e+00, 7.2499657e-01, 8.6576676e-01, 1.1115314e+00],\n",
       "       [7.9047853e-01, 6.3019699e-01, 5.0740272e-01, 2.8926528e-01,\n",
       "        1.5190294e-01, 2.9045111e-01, 3.5318053e-01, 3.7503037e-01],\n",
       "       [2.9201767e-01, 3.0707386e-01, 3.9678290e-01, 5.4324162e-01,\n",
       "        8.6456573e-01, 9.7617674e-01, 6.9843149e-01, 4.4465080e-01],\n",
       "       [4.1351807e-01, 1.8343031e-01, 1.0738023e-01, 8.2689695e-02,\n",
       "        1.2842690e+00, 2.0046597e+00, 9.3442360e-03, 8.3976955e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling of the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_melspec(params, audio_data, sampling_rate):\n",
    "    S = librosa.feature.melspectrogram(audio_data, sr=sampling_rate, n_mels=params['n_mels'],\n",
    "                                      hop_length=params['hop_length'], n_fft=params['n_fft'],\n",
    "                                      fmin=params['fmin'], fmax=(sampling_rate//2))\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    S_dB = S_dB.astype(np.float32)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(single_file):\n",
    "    # Take in count that our dataset files lasts everyone of them the same time. If not you should do something.\n",
    "    audio, sr = librosa.load(single_file, duration=5.0)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    melspec_params = {\n",
    "        'n_mels': 128, # The entire frequency spectrum divided by a concrete number.\n",
    "        'duration': 5*22050, # Number of seconds * sample rate\n",
    "        'hop_length': 512, # It has something to do with the duration. I think it fills the space with repetitions\n",
    "        'n_fft': 2048, # Length of the Fast Fourier Transformation\n",
    "        'fmin': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = os.listdir('../Datasets/s_a_d__datasets/audio_esc50')\n",
    "paths_list = []\n",
    "for file in files_list:\n",
    "    paths_list.append('../Datasets/s_a_d__datasets/audio_esc50/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, path in zip(files_list, paths_list):\n",
    "    audio_file, sr = load_audio(path)\n",
    "    melspec = create_melspec(melspec_params, audio_file, sr)\n",
    "    df = pd.DataFrame(melspec)\n",
    "    df.to_csv('../Datasets/s_a_d__datasets/experimental/' + file[:-4]+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The brand new Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list_csv = os.listdir('../Datasets/s_a_d__datasets/experimental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = []\n",
    "Labels = []\n",
    "\n",
    "for file in files_list_csv:\n",
    "    image_to_be = pd.read_csv('../Datasets/s_a_d__datasets/experimental/'+file)\n",
    "    Images.append(np.mean(image_to_be.to_numpy().T, axis=0))\n",
    "    Labels.append(re.split(r'-|\\.', file)[3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.asarray(Images)\n",
    "Labels = np.asarray(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parentesis. Try a LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Images, Labels, test_size=0.3, stratify=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toni_domenech/Python/envs/s_a_d/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "score = logisticreg.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 128)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1400, 16, 8, 1)\n",
    "X_test = X_test.reshape(600, 16, 8, 1)\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "input_dim = (16,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(50, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='accuracy', patience=8, verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.4732 - accuracy: 0.1036\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.7136 - accuracy: 0.2464\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.4091 - accuracy: 0.3107\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.1096 - accuracy: 0.3857\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.8854 - accuracy: 0.4514\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6937 - accuracy: 0.5036\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5026 - accuracy: 0.5629\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3507 - accuracy: 0.6121\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.2433 - accuracy: 0.6436\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1303 - accuracy: 0.6829\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.0274 - accuracy: 0.7086\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.9514 - accuracy: 0.7414\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.8831 - accuracy: 0.7507\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.8065 - accuracy: 0.7729\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.7752 - accuracy: 0.7786\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.7211 - accuracy: 0.7943\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.6851 - accuracy: 0.8043\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6518 - accuracy: 0.8071\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.6112 - accuracy: 0.8164\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.5722 - accuracy: 0.8357\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.5395 - accuracy: 0.8357\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.5285 - accuracy: 0.8436\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.5014 - accuracy: 0.8550\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.4888 - accuracy: 0.8664\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.4550 - accuracy: 0.8664\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.4334 - accuracy: 0.8679\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3967 - accuracy: 0.8979\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.4053 - accuracy: 0.8850\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.3893 - accuracy: 0.8900\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.4100 - accuracy: 0.8793\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.8700\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.4922 - accuracy: 0.8550\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.4578 - accuracy: 0.8671\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.4266 - accuracy: 0.8693\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3671 - accuracy: 0.8971\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3587 - accuracy: 0.9000\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3535 - accuracy: 0.8986\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3274 - accuracy: 0.9043\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.2930 - accuracy: 0.9164\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.2815 - accuracy: 0.9214\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.2797 - accuracy: 0.9107\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2817 - accuracy: 0.9150\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2746 - accuracy: 0.9179\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2473 - accuracy: 0.9264\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2440 - accuracy: 0.9264\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2328 - accuracy: 0.9307\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2292 - accuracy: 0.9293\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2491 - accuracy: 0.9257\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.2247 - accuracy: 0.9336\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.2121 - accuracy: 0.9414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3d01db790>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 4.0021 - accuracy: 0.4283\n",
      "[4.002133846282959, 0.4283333420753479]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have clearly overfitted our data. We can see it in the difference between the accuracy on the train set and the one in the test set.**\n",
    "\n",
    "In order to solve this we can do two different things. Simplify the model or use more data. We are going to multiply the size of our data.\n",
    "\n",
    "In our first simplification of the problem we did the mean on the intensity axis only. So we had eliminated the time one. It's ok if we only see the intensity but it's worth nothing that the sound have an order in space. So if we do little frames of time we could do a growth in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, sr = librosa.load('../Datasets/s_a_d__datasets/audio_esc50/1-100210-B-36.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = librosa.feature.melspectrogram(y=dat, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_1 = np.mean(arr[:,:128].T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_2 = np.mean(arr[:,128:].T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_algo = []\n",
    "for i in range (len(algo_1)):\n",
    "    def_algo.append(algo_1[i])\n",
    "    def_algo.append(algo_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_algo = np.asarray(def_algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = []\n",
    "Labels = []\n",
    "\n",
    "for file in files_list_csv:\n",
    "    image_to_be = pd.read_csv('../Datasets/s_a_d__datasets/experimental/' + file)\n",
    "    image_to_be = np.asarray(image_to_be)\n",
    "    first_array = np.mean(image_to_be[:,:128].T, axis=0)\n",
    "    second_array = np.mean(image_to_be[:,128:].T, axis=0)\n",
    "    def_array = []\n",
    "    for i in range(len(first_array)):\n",
    "        def_array.append(first_array[i])\n",
    "        def_array.append(second_array[i])\n",
    "    Images.append(def_array)\n",
    "    Labels.append(re.split(r'-|\\.', file)[3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.asarray(Images)\n",
    "Labels = np.asarray(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Images, Labels, test_size=0.3, stratify=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1400, 16, 16, 1)\n",
    "X_test = X_test.reshape(600, 16, 16, 1)\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "input_dim = (16,16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(50, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='accuracy', patience=8, verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 3.3552 - accuracy: 0.1371\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.5247 - accuracy: 0.3007\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 2.1177 - accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.7681 - accuracy: 0.4921\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.5601 - accuracy: 0.5379\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.3676 - accuracy: 0.6086\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.2004 - accuracy: 0.6479\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 1.0820 - accuracy: 0.6886\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.9445 - accuracy: 0.7307\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.8478 - accuracy: 0.7650\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.8035 - accuracy: 0.7686\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.7282 - accuracy: 0.8014\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.6757 - accuracy: 0.8121\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.6201 - accuracy: 0.8286\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5908 - accuracy: 0.8421\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.5600 - accuracy: 0.8479\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.5348 - accuracy: 0.8550\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5327 - accuracy: 0.8550\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.5586 - accuracy: 0.8350\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.5495 - accuracy: 0.8400\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.5162 - accuracy: 0.8550\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.4832 - accuracy: 0.8650\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.4400 - accuracy: 0.8700\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.4225 - accuracy: 0.8750\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3860 - accuracy: 0.8907\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3417 - accuracy: 0.9029\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.3250 - accuracy: 0.9064\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.3191 - accuracy: 0.9093\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2892 - accuracy: 0.9207\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2874 - accuracy: 0.9179\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2738 - accuracy: 0.9250\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2813 - accuracy: 0.9186\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2480 - accuracy: 0.9279\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2304 - accuracy: 0.9364\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2400 - accuracy: 0.9243\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2282 - accuracy: 0.9357\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2206 - accuracy: 0.9364\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1929 - accuracy: 0.9536\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1981 - accuracy: 0.9457\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.2439 - accuracy: 0.9293\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.3361 - accuracy: 0.9164\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.5495 - accuracy: 0.8514\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.5316 - accuracy: 0.8571\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.4602 - accuracy: 0.8771\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.3821 - accuracy: 0.9000\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2851 - accuracy: 0.9200\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.2453 - accuracy: 0.9279\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 1s 33ms/step - loss: 0.2121 - accuracy: 0.9379\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.2042 - accuracy: 0.9371\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1631 - accuracy: 0.9529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f367c525790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 4.8380 - accuracy: 0.4083\n",
      "[4.83804988861084, 0.40833333134651184]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we haven't imporved too much (or nothing) our previous result. But that's because there aren't many sounds lasting 2.5 seconds. Maybe if we can zoom in the sound (using 4, 8 or 16 cuts instead of 1) the result will improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_cuts(number_of_cuts, list_of_files):\n",
    "    cut_size = 216//number_of_cuts\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    for file in list_of_files:\n",
    "        image_to_be = pd.read_csv('../Datasets/s_a_d__datasets/experimental/' + file)\n",
    "        image_to_be = np.asarray(image_to_be)\n",
    "    \n",
    "        cuts = [[] for i in range(number_of_cuts)]\n",
    "        \n",
    "        for  i in range(number_of_cuts):\n",
    "            cuts[i] = np.mean(image_to_be[:,i*cut_size:(i+1)*cut_size].T, axis=0)\n",
    "    \n",
    "        def_array = []\n",
    "        for i in range(len(cuts[0])):\n",
    "            for j in range(len(cuts)):\n",
    "                def_array.append(cuts[j][i])\n",
    "        Labels.append(re.split(r'-|\\.', file)[3])\n",
    "        Images.append(def_array)\n",
    "    Images = np.asarray(Images)\n",
    "    Labels = np.asarray(Labels)\n",
    "    Labels = pd.get_dummies(Labels)\n",
    "    return Images, Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images, Labels = audio_cuts(8, files_list_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Images, Labels, test_size=0.3, stratify=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1400, 32, 32, 1)\n",
    "X_test = X_test.reshape(600, 32, 32, 1)\n",
    "\n",
    "\n",
    "input_dim = (32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(50, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "20/20 [==============================] - 5s 229ms/step - loss: 3.6070 - accuracy: 0.0899 - val_loss: 3.0140 - val_accuracy: 0.1924\n",
      "Epoch 2/8\n",
      "20/20 [==============================] - 4s 223ms/step - loss: 2.4983 - accuracy: 0.2993 - val_loss: 2.4658 - val_accuracy: 0.3088\n",
      "Epoch 3/8\n",
      "20/20 [==============================] - 5s 251ms/step - loss: 1.8483 - accuracy: 0.4719 - val_loss: 2.5308 - val_accuracy: 0.3088\n",
      "Epoch 4/8\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 1.3889 - accuracy: 0.5812 - val_loss: 2.4498 - val_accuracy: 0.3824\n",
      "Epoch 5/8\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 1.0697 - accuracy: 0.6691 - val_loss: 2.5093 - val_accuracy: 0.3658\n",
      "Epoch 6/8\n",
      "20/20 [==============================] - 5s 259ms/step - loss: 0.8767 - accuracy: 0.7508 - val_loss: 2.4830 - val_accuracy: 0.3753\n",
      "Epoch 7/8\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.7532 - accuracy: 0.7732 - val_loss: 2.4807 - val_accuracy: 0.3919\n",
      "Epoch 8/8\n",
      "20/20 [==============================] - 5s 251ms/step - loss: 0.6035 - accuracy: 0.8192 - val_loss: 2.6343 - val_accuracy: 0.3729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f10221de4f0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=50, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 35ms/step - loss: 3.0352 - accuracy: 0.3467\n",
      "[3.0351672172546387, 0.3466666638851166]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing the images complete to a simpler architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = []\n",
    "Labels = []\n",
    "\n",
    "for file in files_list_csv:\n",
    "    image_to_be = pd.read_csv('../Datasets/s_a_d__datasets/experimental/'+file)\n",
    "    Images.append(image_to_be.to_numpy())\n",
    "    Labels.append(re.split(r'-|\\.', file)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = np.asarray(Images)\n",
    "Labels = np.asarray(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.get_dummies(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-401fffbed31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Images, Labels, test_size=0.3, stratify=Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1400, 128, 217, 1)\n",
    "X_test = X_test.reshape(600, 128, 217, 1)\n",
    "\n",
    "\n",
    "input_dim = (128,217,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = ([128, 217, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = (128, 217, 1)))\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(50, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='accuracy', patience=8, verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 128, 217, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 217, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 64, 108, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 108, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 108, 128)      147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 32, 54, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                51250     \n",
      "=================================================================\n",
      "Total params: 442,354\n",
      "Trainable params: 442,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 159s 4s/step - loss: 3.7389 - accuracy: 0.0343\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 171s 4s/step - loss: 3.4418 - accuracy: 0.0586\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 201s 5s/step - loss: 3.2350 - accuracy: 0.1064\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 185s 5s/step - loss: 2.9914 - accuracy: 0.1371\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 190s 5s/step - loss: 2.7733 - accuracy: 0.1886\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 188s 5s/step - loss: 2.6648 - accuracy: 0.2057\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 202s 5s/step - loss: 2.5613 - accuracy: 0.2207\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 208s 5s/step - loss: 2.4907 - accuracy: 0.2407\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 179s 5s/step - loss: 2.4679 - accuracy: 0.2486\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 179s 5s/step - loss: 2.4013 - accuracy: 0.2700\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 184s 5s/step - loss: 2.3149 - accuracy: 0.2914\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 180s 5s/step - loss: 2.2069 - accuracy: 0.3179\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 2.1863 - accuracy: 0.3307\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 2.0994 - accuracy: 0.3407\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 2.0322 - accuracy: 0.3650\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 179s 5s/step - loss: 1.9141 - accuracy: 0.4200\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 180s 5s/step - loss: 1.9025 - accuracy: 0.3929\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 189s 5s/step - loss: 1.8354 - accuracy: 0.4236\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 195s 5s/step - loss: 1.7424 - accuracy: 0.4571\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.6831 - accuracy: 0.4700\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 183s 5s/step - loss: 1.6314 - accuracy: 0.4886\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.6166 - accuracy: 0.4936\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.6253 - accuracy: 0.4743\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.5753 - accuracy: 0.4936\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.5828 - accuracy: 0.5014\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.5064 - accuracy: 0.5143\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.4620 - accuracy: 0.5300\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.4215 - accuracy: 0.5443\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.3711 - accuracy: 0.5614\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.4044 - accuracy: 0.5429\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 1.3297 - accuracy: 0.5579\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 182s 5s/step - loss: 1.2935 - accuracy: 0.5907\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 191s 5s/step - loss: 1.3427 - accuracy: 0.5743\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 192s 5s/step - loss: 1.3071 - accuracy: 0.5814\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 192s 5s/step - loss: 1.2186 - accuracy: 0.5893\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 186s 5s/step - loss: 1.1526 - accuracy: 0.6293\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 188s 5s/step - loss: 1.1679 - accuracy: 0.6136\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 190s 5s/step - loss: 1.1833 - accuracy: 0.6086\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 190s 5s/step - loss: 1.2057 - accuracy: 0.5864\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 182s 5s/step - loss: 1.1658 - accuracy: 0.6107\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 180s 5s/step - loss: 1.1567 - accuracy: 0.6036\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 180s 5s/step - loss: 1.1044 - accuracy: 0.6300\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 180s 5s/step - loss: 1.0279 - accuracy: 0.6629\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 180s 5s/step - loss: 0.9775 - accuracy: 0.6893\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 177s 5s/step - loss: 1.0065 - accuracy: 0.6557\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 0.9584 - accuracy: 0.6850\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 0.9551 - accuracy: 0.6757\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 0.9564 - accuracy: 0.6850\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 0.9624 - accuracy: 0.6779\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 178s 5s/step - loss: 0.9294 - accuracy: 0.6814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc8c3dcd30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=36, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 19s 982ms/step - loss: 1.8190 - accuracy: 0.5000\n",
      "[1.8190422058105469, 0.5]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30000, 600]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-5a5269d3c7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Python/envs/s_a_d/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/envs/s_a_d/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/envs/s_a_d/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/envs/s_a_d/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30000, 600]"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "confusion_matrix(y_test ,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 24, 21, 37,  9, 47,  8, 13,  9, 32, 14, 43,  1, 24, 46,  3, 40,\n",
       "       17, 30, 43, 20, 44, 24, 14, 31,  1, 24, 47,  1, 25, 26, 37, 20, 21,\n",
       "       37, 24,  0,  2, 28, 34, 14, 34, 44,  3, 44, 29, 18, 40,  5,  3, 20,\n",
       "       36, 12, 46, 18, 24, 17,  6, 10, 37, 30, 37,  8, 44, 25,  1, 15,  1,\n",
       "       30, 46, 48, 35, 43, 33, 31, 39,  2, 46, 37, 14, 26, 36, 22, 37,  6,\n",
       "       12, 43, 11, 25, 26,  9,  1, 11,  4, 17, 14,  1, 20, 30, 11, 10, 37,\n",
       "       14, 11, 10, 39,  1, 39, 39, 40, 30, 47, 12, 29, 14, 33, 19, 23, 46,\n",
       "       13, 22, 47, 15, 25,  2, 44, 30,  5,  1, 43, 37, 24,  6, 18, 28, 39,\n",
       "        4, 31, 36, 47,  7,  9, 39, 24, 37, 32, 37, 26, 25, 24, 20,  6, 19,\n",
       "        2, 36, 43, 24, 46, 47,  9, 17, 32, 26, 33, 43,  6,  9, 37,  7, 29,\n",
       "       21, 10, 15,  4, 34,  2, 39,  1, 25, 40, 32, 32, 37, 18, 14, 37, 21,\n",
       "       17, 47,  9, 16, 21, 10, 39, 46, 44, 11, 34, 25, 18,  4, 17, 19, 25,\n",
       "       47, 24, 21, 29, 34,  1,  6, 10, 21, 30, 24,  1, 22, 13, 43, 18,  1,\n",
       "       17, 21,  1, 18, 20, 44,  8, 39, 44,  5, 30, 24, 47, 37, 39, 26, 19,\n",
       "       17, 37, 37, 14, 30, 11, 10, 47, 29, 16, 21, 12, 36, 21, 40,  3, 31,\n",
       "        7, 40, 25, 29, 24, 35, 37,  4, 32, 10, 32, 29, 37, 24, 39, 34, 46,\n",
       "       21, 37, 30, 19, 43, 46, 28, 22,  2, 32,  2, 26,  6, 39,  2,  9,  9,\n",
       "       10,  5, 18, 47, 37, 43, 34, 46, 40, 30,  9, 14, 38, 30, 32,  5, 17,\n",
       "       37, 12, 15, 46, 30, 37, 21, 24,  0, 20, 32, 10, 25, 22, 17, 47, 10,\n",
       "       26,  5,  9, 15, 25, 30, 12, 30, 21,  2, 37, 37, 36, 14, 21, 30,  2,\n",
       "        9, 47, 28,  6, 37,  7,  6,  6, 32, 15, 28, 37, 49, 29, 11, 32, 39,\n",
       "        1, 49, 15, 20, 25,  8, 34, 36, 11,  9, 47,  6, 19,  2, 46, 15, 46,\n",
       "       21, 38, 40, 23, 20, 24,  9, 30,  5, 29, 45, 15,  9,  1, 39,  1, 14,\n",
       "       21,  0, 30, 10, 31, 47, 39, 37, 18, 46,  6, 12, 31,  2,  2,  7, 40,\n",
       "       32, 34, 36, 47, 21, 47,  9,  4,  0, 17, 38,  6, 16, 39,  2, 46, 14,\n",
       "        0, 39, 25,  6, 17,  9,  9,  1, 20,  6, 28, 24, 13, 11, 47, 21, 47,\n",
       "        1,  8,  3,  8,  4,  1, 10,  9, 45, 24, 39, 29, 10, 39, 34, 28, 37,\n",
       "       34, 38, 48, 44, 34, 17, 49, 26, 30, 37, 25, 47, 17,  1, 19,  6, 47,\n",
       "       22,  1, 40, 28,  2, 36,  3, 39, 34, 44, 47, 45, 25, 10, 42, 46, 21,\n",
       "       20,  9,  4, 44, 21, 22, 43, 26, 37, 26, 44, 48, 11, 17,  1,  6,  9,\n",
       "       24, 25,  9, 20, 34, 25,  8, 25, 10, 34, 19, 37, 24, 30, 37,  3, 21,\n",
       "       15, 24, 35,  2, 15, 35, 22, 26,  4, 47, 46, 32, 31, 21, 25,  1, 47,\n",
       "       19, 15, 28, 34, 30,  6, 44, 47, 35,  6,  0, 45,  3, 24, 40, 28,  7,\n",
       "       47, 30, 30, 49, 39, 37, 45,  1, 40, 39,  9, 37,  2, 31, 35, 10, 37,\n",
       "       37, 18, 25, 49,  9, 28, 44, 13,  5, 11,  9, 46,  5, 21, 26,  6, 12,\n",
       "       37, 29, 37, 18,  9])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.stack().reset_index().drop(0,1)['level_1'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to paramter tunning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we are going to try it with different activation funcitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", input_shape = (128, 217, 1)))\n",
    "model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dense(50, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='accuracy', patience=5, verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 [==============================] - 146s 4s/step - loss: 3.8624 - accuracy: 0.0286\n",
      "Epoch 2/50\n",
      "39/39 [==============================] - 146s 4s/step - loss: 3.7397 - accuracy: 0.0550\n",
      "Epoch 3/50\n",
      "39/39 [==============================] - 188s 5s/step - loss: 3.6024 - accuracy: 0.0736\n",
      "Epoch 4/50\n",
      "39/39 [==============================] - 191s 5s/step - loss: 3.4642 - accuracy: 0.0950\n",
      "Epoch 5/50\n",
      "39/39 [==============================] - 199s 5s/step - loss: 3.2238 - accuracy: 0.1164\n",
      "Epoch 6/50\n",
      "39/39 [==============================] - 181s 5s/step - loss: 3.0859 - accuracy: 0.1443\n",
      "Epoch 7/50\n",
      "39/39 [==============================] - 184s 5s/step - loss: 3.0260 - accuracy: 0.1607\n",
      "Epoch 8/50\n",
      "39/39 [==============================] - 181s 5s/step - loss: 2.8837 - accuracy: 0.1993\n",
      "Epoch 9/50\n",
      "39/39 [==============================] - 209s 5s/step - loss: 2.7711 - accuracy: 0.1814\n",
      "Epoch 10/50\n",
      "39/39 [==============================] - 354s 9s/step - loss: 2.6929 - accuracy: 0.2350\n",
      "Epoch 11/50\n",
      "39/39 [==============================] - 362s 9s/step - loss: 2.5951 - accuracy: 0.2521\n",
      "Epoch 12/50\n",
      "39/39 [==============================] - 380s 10s/step - loss: 2.4847 - accuracy: 0.2750\n",
      "Epoch 13/50\n",
      "39/39 [==============================] - 361s 9s/step - loss: 2.4404 - accuracy: 0.2800\n",
      "Epoch 14/50\n",
      "39/39 [==============================] - 349s 9s/step - loss: 2.3495 - accuracy: 0.3014\n",
      "Epoch 15/50\n",
      "39/39 [==============================] - 264s 7s/step - loss: 2.4031 - accuracy: 0.3000\n",
      "Epoch 16/50\n",
      "39/39 [==============================] - 173s 4s/step - loss: 2.3390 - accuracy: 0.3100\n",
      "Epoch 17/50\n",
      "39/39 [==============================] - 171s 4s/step - loss: 2.1619 - accuracy: 0.3514\n",
      "Epoch 18/50\n",
      "39/39 [==============================] - 226s 6s/step - loss: 2.0283 - accuracy: 0.3771\n",
      "Epoch 19/50\n",
      "39/39 [==============================] - 596s 15s/step - loss: 1.9450 - accuracy: 0.4207\n",
      "Epoch 20/50\n",
      "39/39 [==============================] - 314s 8s/step - loss: 1.8759 - accuracy: 0.4321\n",
      "Epoch 21/50\n",
      "39/39 [==============================] - 318s 8s/step - loss: 1.8134 - accuracy: 0.4286\n",
      "Epoch 22/50\n",
      "39/39 [==============================] - 318s 8s/step - loss: 1.6329 - accuracy: 0.4871\n",
      "Epoch 23/50\n",
      "39/39 [==============================] - 318s 8s/step - loss: 1.6333 - accuracy: 0.4857\n",
      "Epoch 24/50\n",
      "39/39 [==============================] - 179s 5s/step - loss: 1.6392 - accuracy: 0.4864\n",
      "Epoch 25/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.6337 - accuracy: 0.5079\n",
      "Epoch 26/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.5797 - accuracy: 0.5157\n",
      "Epoch 27/50\n",
      "39/39 [==============================] - 168s 4s/step - loss: 1.5013 - accuracy: 0.5407\n",
      "Epoch 28/50\n",
      "39/39 [==============================] - 169s 4s/step - loss: 1.4072 - accuracy: 0.5757\n",
      "Epoch 29/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.2852 - accuracy: 0.6000\n",
      "Epoch 30/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.2978 - accuracy: 0.5907\n",
      "Epoch 31/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.3077 - accuracy: 0.5950\n",
      "Epoch 32/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.1846 - accuracy: 0.6179\n",
      "Epoch 33/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.1092 - accuracy: 0.6471\n",
      "Epoch 34/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.1372 - accuracy: 0.6393\n",
      "Epoch 35/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 1.0748 - accuracy: 0.6543\n",
      "Epoch 36/50\n",
      "39/39 [==============================] - 168s 4s/step - loss: 1.1159 - accuracy: 0.6700\n",
      "Epoch 37/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.9722 - accuracy: 0.6857\n",
      "Epoch 38/50\n",
      "39/39 [==============================] - 168s 4s/step - loss: 0.9646 - accuracy: 0.6893\n",
      "Epoch 39/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.9113 - accuracy: 0.7050\n",
      "Epoch 40/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.8608 - accuracy: 0.7321\n",
      "Epoch 41/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.8761 - accuracy: 0.7193\n",
      "Epoch 42/50\n",
      "39/39 [==============================] - 168s 4s/step - loss: 0.8655 - accuracy: 0.7207\n",
      "Epoch 43/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.8749 - accuracy: 0.7079\n",
      "Epoch 44/50\n",
      "39/39 [==============================] - 168s 4s/step - loss: 0.7441 - accuracy: 0.7593\n",
      "Epoch 45/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.6934 - accuracy: 0.7721\n",
      "Epoch 46/50\n",
      "39/39 [==============================] - 167s 4s/step - loss: 0.7151 - accuracy: 0.7707\n",
      "Epoch 47/50\n",
      "39/39 [==============================] - 266s 7s/step - loss: 0.6573 - accuracy: 0.7864\n",
      "Epoch 48/50\n",
      "39/39 [==============================] - 323s 8s/step - loss: 0.7454 - accuracy: 0.7450\n",
      "Epoch 49/50\n",
      "39/39 [==============================] - 321s 8s/step - loss: 0.7551 - accuracy: 0.7621\n",
      "Epoch 50/50\n",
      "39/39 [==============================] - 260s 7s/step - loss: 0.7731 - accuracy: 0.7479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1eaeeb64c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=36, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 17s 904ms/step - loss: 2.6138 - accuracy: 0.5550\n",
      "[2.613813877105713, 0.5550000071525574]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
